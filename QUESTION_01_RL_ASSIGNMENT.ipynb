{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHpKm0435bsw",
        "outputId": "41b229bb-7e93-422b-dc81-b4d9a776af48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal Policy (Policy Iteration):\n",
            "['east', 'north', 'west', 'north', 'west']\n",
            "['east', 'north', 'north', 'west', 'west']\n",
            "['east', 'north', 'north', 'north', 'north']\n",
            "['east', 'north', 'north', 'north', 'north']\n",
            "['east', 'north', 'north', 'north', 'north']\n",
            "Optimal Value Function (Value Iteration):\n",
            "[21.98, 24.42, 21.98, 19.42, 17.48]\n",
            "[19.78, 21.98, 19.78, 17.8, 16.02]\n",
            "[17.8, 19.78, 17.8, 16.02, 14.42]\n",
            "[16.02, 17.8, 16.02, 14.42, 12.98]\n",
            "[14.42, 16.02, 14.42, 12.98, 11.68]\n",
            "Optimal Policy (Value Iteration):\n",
            "['east', 'north', 'west', 'north', 'west']\n",
            "['east', 'north', 'north', 'west', 'west']\n",
            "['east', 'north', 'north', 'north', 'north']\n",
            "['east', 'north', 'north', 'north', 'north']\n",
            "['east', 'north', 'north', 'north', 'north']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the gridworld parameters\n",
        "gamma = 0.9  # discount factor\n",
        "reward_off_grid = -1\n",
        "reward_A = 10\n",
        "reward_B = 5\n",
        "\n",
        "# Grid dimensions\n",
        "grid_size = (5, 5)\n",
        "\n",
        "# Special states\n",
        "A = (0, 1)\n",
        "A_prime = (4, 1)\n",
        "B = (0, 3)\n",
        "B_prime = (2, 3)\n",
        "\n",
        "# Define the state space\n",
        "states = [(i, j) for i in range(grid_size[0]) for j in range(grid_size[1])]\n",
        "\n",
        "# Define the action space\n",
        "actions = ['north', 'south', 'east', 'west']\n",
        "action_effects = {\n",
        "    'north': (-1, 0),\n",
        "    'south': (1, 0),\n",
        "    'east': (0, 1),\n",
        "    'west': (0, -1)\n",
        "}\n",
        "\n",
        "# Initialize value function\n",
        "V = {s: 0 for s in states}\n",
        "\n",
        "# Define the transition function\n",
        "def transition(state, action):\n",
        "    if state == A:\n",
        "        return A_prime, reward_A\n",
        "    elif state == B:\n",
        "        return B_prime, reward_B\n",
        "\n",
        "    effect = action_effects[action]\n",
        "    new_state = (state[0] + effect[0], state[1] + effect[1])\n",
        "\n",
        "    if new_state[0] < 0 or new_state[0] >= grid_size[0] or new_state[1] < 0 or new_state[1] >= grid_size[1]:\n",
        "        return state, reward_off_grid\n",
        "\n",
        "    return new_state, 0\n",
        "\n",
        "# Policy Iteration\n",
        "\n",
        "# Initialize policy to random (e.g., always move north)\n",
        "policy = {s: np.random.choice(actions) for s in states}\n",
        "\n",
        "def policy_evaluation(policy, V, gamma=0.9, theta=1e-8):\n",
        "    while True:\n",
        "        delta = 0\n",
        "        for s in states:\n",
        "            v = V[s]\n",
        "            a = policy[s]\n",
        "            s_next, r = transition(s, a)\n",
        "            V[s] = r + gamma * V[s_next]\n",
        "            delta = max(delta, abs(v - V[s]))\n",
        "        if delta < theta:\n",
        "            break\n",
        "    return V\n",
        "\n",
        "def policy_improvement(policy, V, gamma=0.9):\n",
        "    policy_stable = True\n",
        "    for s in states:\n",
        "        old_action = policy[s]\n",
        "        action_values = {}\n",
        "        for a in actions:\n",
        "            s_next, r = transition(s, a)\n",
        "            action_values[a] = r + gamma * V[s_next]\n",
        "        best_action = max(action_values, key=action_values.get)\n",
        "        policy[s] = best_action\n",
        "        if old_action != best_action:\n",
        "            policy_stable = False\n",
        "    return policy, policy_stable\n",
        "\n",
        "# Policy Iteration Algorithm\n",
        "while True:\n",
        "    V = policy_evaluation(policy, V)\n",
        "    policy, policy_stable = policy_improvement(policy, V)\n",
        "    if policy_stable:\n",
        "        break\n",
        "\n",
        "# Print the optimal policy\n",
        "print(\"Optimal Policy (Policy Iteration):\")\n",
        "for i in range(grid_size[0]):\n",
        "    print([policy[(i, j)] for j in range(grid_size[1])])\n",
        "\n",
        "# Value Iteration\n",
        "V = {s: 0 for s in states}\n",
        "\n",
        "def value_iteration(V, gamma=0.9, theta=1e-8):\n",
        "    while True:\n",
        "        delta = 0\n",
        "        for s in states:\n",
        "            v = V[s]\n",
        "            action_values = []\n",
        "            for a in actions:\n",
        "                s_next, r = transition(s, a)\n",
        "                action_values.append(r + gamma * V[s_next])\n",
        "            V[s] = max(action_values)\n",
        "            delta = max(delta, abs(v - V[s]))\n",
        "        if delta < theta:\n",
        "            break\n",
        "    return V\n",
        "\n",
        "V = value_iteration(V)\n",
        "\n",
        "# Print the value function\n",
        "print(\"Optimal Value Function (Value Iteration):\")\n",
        "for i in range(grid_size[0]):\n",
        "    print([round(V[(i, j)], 2) for j in range(grid_size[1])])\n",
        "\n",
        "\n",
        "\n",
        "# Extract the policy from the value function\n",
        "optimal_policy_vi = {}\n",
        "for s in states:\n",
        "    action_values = {}\n",
        "    for a in actions:\n",
        "        s_next, r = transition(s, a)\n",
        "        action_values[a] = r + gamma * V[s_next]\n",
        "    optimal_policy_vi[s] = max(action_values, key=action_values.get)\n",
        "\n",
        "\n",
        "\n",
        "# Print the optimal policy from value iteration\n",
        "print(\"Optimal Policy (Value Iteration):\")\n",
        "for i in range(grid_size[0]):\n",
        "    print([optimal_policy_vi[(i, j)] for j in range(grid_size[1])])\n"
      ]
    }
  ]
}